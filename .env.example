# LLM Listener Configuration
# Copy this file to .env and fill in your API keys

# API Keys (at least one must be set)
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here
GEMINI_API_KEY=your-gemini-key-here

# Ollama (local models - no API key needed)
OLLAMA_ENABLED=false
OLLAMA_BASE_URL=http://localhost:11434

# Optional: Override default models
# OPENAI_MODEL=gpt-4o
# ANTHROPIC_MODEL=claude-sonnet-4-20250514
# GEMINI_MODEL=gemini-1.5-pro
# OLLAMA_MODEL=llama3.2

# Optional: Which provider to use for reconciliation
# Options: openai, anthropic, gemini
# RECONCILER_PROVIDER=anthropic

# ============================================
# Authentication Configuration (Auth0 / OIDC)
# ============================================

# Auth0 domain and credentials (get from Auth0 admin)
AUTH0_DOMAIN=resilienthub.us.auth0.com
AUTH0_CLIENT_ID=your-client-id-here
AUTH0_CLIENT_SECRET=your-client-secret-here

# API audience (optional - for API access tokens)
# AUTH0_AUDIENCE=https://prism-chorus.resilienthub.org

# Application URLs
APP_URL=http://localhost:5173
API_URL=http://localhost:8000

# Session configuration
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SESSION_SECRET_KEY=your-secret-key-here
SESSION_MAX_AGE=86400

# Role claim configuration (custom namespace in Auth0)
ROLE_CLAIM_NAMESPACE=https://resilienthub.org/claims
DEFAULT_ROLE=viewer

# Authentication requirement
# Set to true when ready to enable auth
AUTH_REQUIRED=false

# ============================================
# App Mode Configuration
# ============================================

# App mode: "prism" (public health + study) or "chorus" (research focus)
APP_MODE=prism
